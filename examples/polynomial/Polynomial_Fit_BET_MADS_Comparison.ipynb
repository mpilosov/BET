{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook recreates the following example using BET:  \n",
    "http://madsjulia.github.io/Mads.jl/Examples/infogap/  \n",
    "See the introduction of the documentation therein for more information about the problem setup. \n",
    "\n",
    "Author: Michael Pilosov  \n",
    "Date: 06-09-2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import numpy as np\n",
    "import bet.calculateP.simpleFunP as simpleFunP\n",
    "import bet.calculateP.calculateP as calculateP\n",
    "import bet.postProcess.plotP as plotP\n",
    "import bet.postProcess.plotDomains as plotD\n",
    "import bet.sample as samp\n",
    "import bet.sampling.basicSampling as bsam\n",
    "from myModel import my_model\n",
    "\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_input_samples = 5E5 # Note 20,000 samples is similar to what the regular grid would use\n",
    "randomSampling = False # random or regular sampling?\n",
    "grid_factor = 10 # for regular sampling only. how many per interval."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define reference parameter. Recall that  \n",
    "$$\n",
    "y(t) = a t^n + bt + c\n",
    "$$\n",
    "\n",
    "The convention of ordering for our parameter $\\lambda$ that we will use is  \n",
    "$$\n",
    "\\lambda = [a, b, c, n]\n",
    "$$\n",
    "\n",
    "Since the data we are trying to match up for $t = [1,2,3,4]$ is $y(t) = [1,2,3,4]$, then we have two cases for $n$ that yield the following analytic solutions:  \n",
    "\n",
    "$$ \n",
    "n = 0 \\implies a+c=0, b=1 \\\\\n",
    "n = 1 \\implies a+b=1, c=0\n",
    "$$\n",
    "\n",
    "We then pick any viable reference parameter and map it to our 4-D output space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4.8894905  1.        -4.8894905  0.       ] => [ 1.  2.  3.  4.]\n"
     ]
    }
   ],
   "source": [
    "a = 10*np.random.rand()-5 # choose any a between -5 and 5\n",
    "# pick any one of the analytical solutions [a,b,c,n]\n",
    "ref_param = np.array([[a, 1.0, -a, 0.0]])\n",
    "# ref_param = np.array([[a, 1.0-a, 0.0, 1.0]])\n",
    "Q_ref =  my_model(np.array(ref_param))\n",
    "print ref_param[0], '=>', Q_ref[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we define the sampler that will be used to create the discretization object, initialize 4-dimensional input parameter sample set object, and set up the parameter space domain (our prior/ansatz is uniform over this space) and generate the (random or regular) samples on which we will later form our probability measure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sampler = bsam.sampler(my_model)\n",
    "input_samples = samp.sample_set(4)\n",
    "input_samples.set_domain(np.array([ [-10.0, 10.0],\n",
    "                                    [-10.0, 10.0], \n",
    "                                    [-5.0, 5.0], \n",
    "                                    [-3.0, 3.0] ]))\n",
    "\n",
    "if randomSampling is True:\n",
    "    input_samples = sampler.random_sample_set('random', input_samples, num_samples=num_input_samples)\n",
    "else:\n",
    "    # if regular sampling, use the integer grid in uncertainty box. 24,000 samples.\n",
    "    input_samples = sampler.regular_sample_set(input_samples, num_samples_per_dim=grid_factor*np.array([20, 20, 10, 6])) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A standard Monte Carlo (MC) assumption is that every Voronoi cell has the same volume. If a regular grid of samples was used, then the standard MC assumption is true. If the number of random samples is large enough for the dimension of the parameter space, the MC assumption is _practically_ true. To have accurate volumes of the randomly generated Voronoi cells, we can use emulation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MC_assumption = True\n",
    "start_time = time.time()\n",
    "# Estimate volumes of Voronoi cells associated with the parameter samples\n",
    "if MC_assumption is False:\n",
    "    input_samples.estimate_volume(n_mc_points=num_input_samples*50.0)\n",
    "else:\n",
    "    input_samples.estimate_volume_mc()\n",
    "\n",
    "# Create the discretization object using the input samples\n",
    "my_full_discretization = sampler.compute_QoI_and_create_discretization(input_samples,\n",
    "                                               savefile = '4to4_discretization.txt.gz')\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'time elapsed:', (end_time - start_time)/60\n",
    "print 'number of unique volumes:', np.unique(my_full_discretization._input_sample_set._volumes).shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define a distribution on our output space, which is $\\pm 1$ in each dimension. The argument `rect_size` refers to the length of the interval, which will thus be 2. The number of cells per dimension raised to the fourth power will determine the number of unique probabilities over the support of the inverse image.  \n",
    "Finally, we calculate the probability measure over the parameter space $\\Lambda$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "QoI_indices = [0,1,2,3]\n",
    "h = 1.0\n",
    "output_disc_cells_per_dim = 2\n",
    "randomDataDiscretization = False\n",
    "\n",
    "# # #\n",
    "output_samples = my_full_discretization._output_sample_set.copy() # grab subset of QoI indices\n",
    "output_samples._dim = len(QoI_indices)\n",
    "output_samples.set_values(output_samples._values[:, QoI_indices])    \n",
    "output_samples.global_to_local()\n",
    "\n",
    "my_discretization = samp.discretization(input_sample_set=input_samples,\n",
    "                                            output_sample_set=output_samples)\n",
    "\n",
    "if randomDataDiscretization is False:\n",
    "    simpleFunP.regular_partition_uniform_distribution_rectangle_size(\n",
    "            data_set=my_discretization, Q_ref=Q_ref[0][QoI_indices], rect_size=2.0*h,\n",
    "            cells_per_dimension = output_disc_cells_per_dim)\n",
    "else:\n",
    "    simpleFunP.uniform_partition_uniform_distribution_rectangle_size(\n",
    "        data_set=my_discretization, Q_ref=Q_ref[0][QoI_indices], rect_size=2.0*h,\n",
    "        M=50, num_d_emulate=1E5)\n",
    "    \n",
    "calculateP.prob(my_discretization)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Extrapolate to t=5 # \n",
    "print 'num unique prob events: ', len(np.unique(input_samples._probabilities))\n",
    "print 'total nonzero probability samples: ', sum(input_samples._probabilities!=0)\n",
    "threshvec = np.sort(np.unique(input_samples._probabilities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "thresh = threshvec[-1] # threshold, [-1] => highest probability only. [1] => nonzero\n",
    "print 'thresh: ', thresh\n",
    "above_thresh = input_samples._probabilities>=thresh\n",
    "print 'num samples with highest probs: ', sum(above_thresh)\n",
    "print 'which represents: ', 100*sum(input_samples._probabilities[above_thresh]), '%% of the total probability'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print sum(my_discretization._input_sample_set._probabilities)\n",
    "# print sum(my_discretization._output_probability_set._probabilities)\n",
    "# print my_discretization._output_probability_set._values\n",
    "\n",
    "# print my_discretization._output_sample_set._values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# range of nonzero probability samples (full pushforward, posterior).\n",
    "samples_nonzero = input_samples._values[input_samples._probabilities>0]\n",
    "t = 5.0\n",
    "print 'Range of nonzero prob events: \\n'\n",
    "extrapolation = samples_nonzero[:,0]*(t**samples_nonzero[:,3]) + samples_nonzero[:,1]*t + samples_nonzero[:,2]\n",
    "print 'Model at t=5, (min, max):', np.min(extrapolation), np.max(extrapolation) \n",
    "print '\\t\\t   range:', np.max(extrapolation)-np.min(extrapolation)\n",
    "\n",
    "# range of just the highest probability samples.\n",
    "samples_thresh = input_samples._values[above_thresh]\n",
    "print '\\nRange of highest prob events: \\n'\n",
    "extrapolation = samples_thresh[:,0]*(t**samples_thresh[:,3]) + samples_thresh[:,1]*t + samples_thresh[:,2]\n",
    "print 'Model at t=5, (min, max):', np.min(extrapolation), np.max(extrapolation) \n",
    "print '\\t\\t   range:', np.max(extrapolation)-np.min(extrapolation)\n",
    "\n",
    "if output_disc_cells_per_dim > 1:\n",
    "    # range of the rest (nonzero but below thresh)\n",
    "    nonzero_below_thresh = np.where( (input_samples._probabilities>0) & (input_samples._probabilities<thresh) )[0]\n",
    "    samples_subset = input_samples._values[nonzero_below_thresh]\n",
    "    print '\\nRange of the rest: \\n'\n",
    "    extrapolation = samples_subset[:,0]*(t**samples_subset[:,3]) + samples_subset[:,1]*t + samples_subset[:,2]\n",
    "    print 'Model at t=5, (min, max):', np.min(extrapolation), np.max(extrapolation) \n",
    "    print '\\t\\t   range:', np.max(extrapolation)-np.min(extrapolation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_disc = 20 # plotting discretization\n",
    "\n",
    "# calculate 2d marginal probs\n",
    "(bins2D, marginals2D) = plotP.calculate_2D_marginal_probs(input_samples,\n",
    "                                                        nbins = plot_disc*np.ones(4))\n",
    "\n",
    "# smooth 2d marginals probs (optional)\n",
    "# marginals2D = plotP.smooth_marginals_2D(marginals2D, bins, sigma=0.2)\n",
    "\n",
    "# plot 2d marginals probs\n",
    "plotP.plot_2D_marginal_probs(marginals2D, bins2D, input_samples, filename = \"linearMap\",\n",
    "                             lam_ref=ref_param[0], file_extension = \".eps\", plot_surface=False)\n",
    "\n",
    "# calculate 1d marginal probs\n",
    "(bins1D, marginals1D) = plotP.calculate_1D_marginal_probs(input_samples,\n",
    "#                                                         nbins = plot_disc*np.ones(4))\n",
    "                                                        nbins = plot_disc*np.array([20, 20, 10, 6]))\n",
    "# smooth 1d marginal probs (optional)\n",
    "marginals1D = plotP.smooth_marginals_1D(marginals1D, bins1D, sigma=0.1)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (16, 16)\n",
    "lambda_label = ['a','b','c','n']\n",
    "f, ax = plt.subplots(4,4)\n",
    "for i in xrange(4):\n",
    "    for j in xrange(4):\n",
    "        lam_domain = input_samples.get_domain()\n",
    "        if i==j:\n",
    "            x_range = np.linspace(lam_domain[i, 0], lam_domain[i, 1],\n",
    "                    len(bins1D[i])-1)\n",
    "            ax[i,j].plot(x_range, marginals1D[i]/(bins1D[i][1]-bins1D[i][0]))\n",
    "#             ax[i,j].set_ylim([0, 1.05*np.max(marginals1D[i]/(bins1D[i][1]-bins1D[i][0]))])\n",
    "            plt.axis([lam_domain[i][0], lam_domain[i][1], \n",
    "                      0, 1.05*np.max(marginals1D[i]/(bins1D[i][1]-bins1D[i][0]))])\n",
    "            ax[i,j].plot(ref_param[0,i], 0.0, 'ko', markersize=5)\n",
    "            ax[i,j].set_ylabel(r'$\\rho$')\n",
    "            ax[i,j].set_xlabel(r'$%s$'%lambda_label[i],fontsize=14)\n",
    "            \n",
    "        elif i<j:\n",
    "#             ax[i,j].scatter(marginals1D[i], marginals1D[j])\n",
    "            boxSize = (bins2D[i][1]-bins2D[i][0])*(bins2D[j][1]-bins2D[j][0])\n",
    "            ax[i,j].imshow(marginals2D[(i,j)]/boxSize, \n",
    "                          interpolation='bicubic', cmap=cm.CMRmap_r, \n",
    "                          extent=[lam_domain[j][0], lam_domain[j][1],\n",
    "                          lam_domain[i][0], lam_domain[i][1]], origin='lower',\n",
    "                          vmax=marginals2D[(i, j)].max()/boxSize, vmin=0, aspect='auto')\n",
    "            ax[i,j].plot(ref_param[0,j], ref_param[0,i], 'bo', markersize=5)\n",
    "            plt.axis([lam_domain[i][0], lam_domain[i][1], lam_domain[j][0],\n",
    "                lam_domain[j][1]])\n",
    "            plt.tight_layout()\n",
    "#             ax[i,j].set_ylabel(r'$%s$'%lambda_label[j])\n",
    "        \n",
    "f.subplots_adjust(hspace=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plt.scatter(marginals1D[0],marginals1D[3])\n",
    "# plt.show()\n",
    "np.unique(input_samples._probabilities)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
